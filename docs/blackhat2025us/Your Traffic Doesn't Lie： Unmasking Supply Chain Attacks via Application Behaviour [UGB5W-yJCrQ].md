# Your Traffic Doesn't Lieï¼š Unmasking Supply Chain Attacks via Application Behaviour [UGB5W-yJCrQ]

Thank you all for that introductionã€‚ I know it's the second day and everyone's kind of slowly moving alongã€‚

 so I appreciate everyone's time to come here about our very exciting projectã€‚

 It's something Colin and I have been working on for the last two yearsã€‚

 It's definitely the most interesting project I've worked onã€‚

 so we're very excited to be here sharing the insights with everyone by way of introductionã€‚

 my name is Dgma Mugetaï¼Œ and I'm here today with my colleague Colin Esepã€‚ðŸ˜Šï¼ŒHi everyoneã€‚

 thanks for comingã€‚I've been at Netco Thrat Labs for about seven years nowã€‚

 and that's been the entirety of my research careerã€‚

One fun fact about me is if you ask me to strap on a parachute and jump out of a planeã€‚

 it's not really a big dealï¼Œ but what I do find terrifyingã€‚Is the solar winds compromiseã€‚

I was at Netcope when this happened and it was the first major incident that happened while I was thereã€‚

Andã€‚Because the Solarwinds customers were probably pretty similarã€‚

 I thought to Netcope customers at the timeï¼Œ it kind of struck me how I'm sure there's plenty of organizations that got hit with this who were what we would consider mature in their security postureã€‚

They hadã€‚Sock analysts evaluating similarsã€‚ they had pen testsï¼Œ they scanned for vulnerabilitiesã€‚

 They did all these thingsã€‚That we're supposed to be doingã€‚And yet this still happenedã€‚

And there was a dwell time of more than a year for this thingã€‚

So that really struck me and like many of the members of the security communityï¼Œ I thoughtã€‚

I've got to do somethingï¼Œ toã€‚Prevent this from happening againã€‚And at the timeã€‚

 I wasn't sure what that wasï¼Œ but it motivated me to kind ofã€‚Think about thatï¼Œ moving forwardã€‚

So that inspired the research that Dimalli and I are going to be talking to you about todayã€‚

So I'll let Dggno go ahead and show you where this research kind of sits in the rest of the landscapeã€‚

Awesomeï¼Œ thank you Kï¼Œ so when we talk about the research that we're going coverã€‚

 it's important to talk about before we do that it's important to talk about what's out there todayã€‚

 So if we look at the software development lifecycle from the developer writing code all the way to the software being packaged and run in your customer or your client environmentã€‚

 there's actually a variety of places a threat might exist a developer's credentials might be compromised and the code might be modified or an attacker might go straight to the source control management system and compromise that or they might bypass the step and modify the code on the way to the CICD system or they might just go ahead and compromise the CICD system itselfã€‚

Or they might go ahead and swap out the artifacts on the way to the distribution endpointã€‚

 or they might just go ahead and compromise the distribution endpoint itselfã€‚

 or they might just skip all of this process altogetherã€‚

 and just swap the application on its way to your client or your customer environmentã€‚

 And if your software is like any other software out there and it has any dependenciesã€‚

 any librariesï¼Œ then all of these threats exist up that dependency chain as wellã€‚

 So when Colin and I got together we started to brainstorm where wed want a detector to be to be put in placeã€‚

 We notice that it's in this use sectionã€‚ right That's where we want to identify a potential compromiseã€‚

 We want to have a control in place that identifies when these applications are behaving anomalously when they're behaving potentially maliciouslyã€‚

 when there's a deviation when there's potential deviation that warrant further investigationã€‚

 And we want to have a way to explain what's going on as wellã€‚

And I'll let Colin go over what this looks likeã€‚Yesã€‚

 so like Doug Maui said we wanted to sit on the right side of the pipelines so this is where software has been deployed and it's on users devices in a real environment and so in most cases you're gonna to have something like the box client just as an example running and it's communicating with B services what we wanted to find was this case where all of a sudden it's not just communicating with B anymore now it's communicating with some other endpoint which could be maliciousã€‚

So that was the goal was to be able to find something like this happening in the networkã€‚

And so if we did find something like that in the networkï¼Œ what is it that we want to seeã€‚

So in our ideal scenario we'd want to see something that told usï¼Œ heyï¼Œ this host at Dgmai IOã€‚

 this communication is anomalous and it would have a certain level of confidenceã€‚

 a certain probability that this is an anomaly so in this case let's just say it's 99% sure that this is an anomaly for the box client and then we'd also want to see the reasons why like how did it arrive at that conclusionã€‚

 what's anomaalous about itã€‚And so there's three examples here on the slide that we'd kind of want to seeã€‚

 we'd want to see something like this where it saysï¼Œ heyã€‚

 you know what the entropy of this URL or the randomness of the characters within the URL is different than what we normally see for boxã€‚

 so that increases the odds by 5 x that this isã€‚An anomalyã€‚The application hostsã€‚

 the typical hosts that this thing communicates with over time associated with the box applicationã€‚

 this is not one of the ones we've seen beforeï¼Œ so that also increases the odds by more than four times and then the path depthã€‚

 this is just saying heyï¼Œ normally there's some file hashes or some API versioning information that box reaches out to when it's communicating with a server and this time it's not the same length it's a root path that it's communicating with and that increases the odds by 3Xã€‚

So if you're anything like meï¼Œ you might see this and sayï¼Œ you know whatã€‚

 this sounds a little bit crazyï¼Œ you want to monitor a huge organization with thousands of employees located all over the world using tons of different appsã€‚

 doing all different activities every single day and you're telling me you want to find that needle in the haystack to tell me this is strange communicationã€‚

That seems like a really difficult problemã€‚So what we foundï¼Œ thoughã€‚

 was that if we broke it down into the applications and profile applications separatelyã€‚

It becomes a bit easierã€‚ This becomes more of a tractable problem to solveã€‚

And so what we did was we started looking at applications individuallyï¼Œ and it turns outï¼Œ you knowã€‚

 they do use the same servers or domains over and over againã€‚

 they use the same HDTP methods over and over againã€‚ So even though there's some variabilityã€‚

 they're somewhat predictable in what they're doing day after dayã€‚

So with all of those things in mind with our approachã€‚

We went ahead and created an open source tool that we're releasing todayã€‚So it's called beamã€‚

 the behavioral evaluation of application metricsã€‚So beamM analyzes network traffic capturesã€‚

 it models the applications in the traffic and detects the compromises that might be happening in those applicationsã€‚

And that's available starting todayã€‚Built into it are application models for8 differentã€‚

 very common applicationsã€‚ So at Netcopeï¼Œ we have a ton of different organizations as our customers all across the world in all different industriesã€‚

And we're able to see what do they use and so we chose eight of the common applications we see all the timeã€‚

 So what this means is that you can go into our repoï¼Œ download the software and deploy itã€‚

 and today you could detect anomalies with any of these applications without any learning periodã€‚

But what we really want to talk about is the research leading up to thisã€‚

 So I'll let Mawing kick that offã€‚ Aï¼Œ thank youï¼Œ Colinã€‚

 So when we talk about the research that went into beamã€‚

 we have to start off by talking about the dataã€‚ Where do we get a lot of these insights that we've gotten is by looking at the data and an Necopeã€‚

 we've been able to curate about data data for about 2000 organizations resulting in about 56 billion transactionsã€‚

 So a transaction here is an HP request responseã€‚ So let's say you have a client application it sends a get request out to a server server responds to 200 some Jsonã€‚

 That request response is what we refer to as a transactionã€‚

 and we have 56 billion of these transactions that we able to get insights fromã€‚

 and these transactions came from 4ã€‚2 million different devicesã€‚ So these are users laptopsï¼Œ desktopã€‚

 serversï¼Œ etcã€‚ And on these devices or running 1ã€‚5 million different native applicationsã€‚

 So these applications are just likeã€‚Coin mentioned these aren't like browsersï¼Œ right These sorryã€‚

 These aren't like cloud provider sitesã€‚ Theyre actually applications people download and install things like Discordã€‚

 the boxï¼Œ clientï¼Œ Slackï¼Œ Spotifyï¼Œ etcterã€‚ And these applications had 7ã€‚

5 million different user agent stringsã€‚ So depending on what device they are running on what version was runningã€‚

 etcï¼Œ they might have a different user agent stringsã€‚ So these 1ã€‚

5 million different applications resulted in 7ã€‚5 million different user agent stringsã€‚

 So as we go alongï¼Œ the rest of the talk when we talk about the dataã€‚ we looked at the dataã€‚

 we got insights from the dataã€‚ This is what we're referring toã€‚So once we have the dataã€‚

 the next thing we did was you followed a threephase approach to building a detectorã€‚

 So we're gonna to slowly walk you through these phases the rest of the talkã€‚

 The first phase was attributionã€‚ So we have these transactions the first thing we have to do is identify which application the transaction came from So to do that we kind of gain some insights from the transaction itself and be able to tag it with the application information once we have these transactions for the applicationã€‚

 The next thing we want to do is collect all of these transactions for the application and kind of build a profile like Colin saidã€‚

 what we want to do is we want to kind of capture the essence of how the application isã€‚

 what does it do What's like the data date looking like for this particular application and once we have what that model for that application for any new transactions that come inã€‚

 we check against what we know to be normal for this application and see if there's a deviation and if there is a deviation is it large enough to be an anomaly and if it isã€‚

Anomalyï¼Œ whyï¼Œ what's the reasoning behind it I' it maliciousã€‚

 And that gives us the insights that then we fashion into a detectorã€‚

 I'll let Colin go over the attribution stepã€‚Yeahï¼Œ so the first step is attribution so what do we mean by attributionã€‚

 what we mean is that we're looking at some network traffic and we want to identify what applications generated that traffic so we have within beam we have a component that does that so I'll talk a little bit about how that worksã€‚

So the first thing we do within the traffic captures is we leverage user agent strengthsã€‚ Nowã€‚

 typicallyï¼Œ this has been avoided by security professionals for a couple of reasonsã€‚

Probably the first reason is that it's editableï¼Œ so if you know how to do itã€‚

 you can modify the user agent string to say anything you wantã€‚

And because of that most people don't trust it rightly soï¼Œ howeverï¼Œ I'll say like we mentionedã€‚

 we have a lot of data at Necope and that data comes from the day-to-day activities of people all over the world in different organizations and these people are not sitting there modifying their user agent string every time they're using Slack or Asana or something like thatã€‚

 so we have a lot of traffic that we have a high level of confidence in that this is the original user agent that comes from the applicationã€‚

So that's the first thingã€‚ The second thing is that user agent strings like we're showing on the screen don't follow any sort of standard structureã€‚

 there's no standard out there that says heyï¼Œ all you vendors that create user agent strings have to adhere to a certain structure so that we can parse it It's just a bunch of textã€‚

 and so it's difficult to deal with so how do we deal with all of thatã€‚Wellã€‚

 we found that experimenting with some LLMsï¼Œ we were able to actually get them to summarize what the user agents meant pretty wellã€‚

And within beamï¼Œ we have a Laama model includedï¼Œ but we also built a connector that goes out to Geminiã€‚

 if you have a Gemini accountã€‚You can use that API as wellã€‚

 So that's one of the ways that we take the user agent string and try to translate it to an application nameã€‚

 We also used some libraries that are available for Python that do this as well and what we want to get to is basically just an application name in a version number So we're translating from the user agent down to just say Chrome 134 or B or something like thatã€‚

So that's the first step in the process and I'll let Deb Mai walk you through the next step where we model these applications Awesomeã€‚

 thank you Colin so now we have the transactions and we've tagged these transactions with the application that it's coming from the next bit we want to do is like we talked about we want to build a model for these applications and we do this by a model training phase so when we started to look at what sort of signals do we want to extract from these transactions Conin and I kind of got together and we started making a list so we definitely want to identify any unusual domain connections that might be happening similar to the sunburst malware we want to see any anomalous repo access that might be happening like the 3CX attack and we absolutely want to see any large outbound unexpected data transfer that might be happening similar to the MoVID incidentã€‚

So when we started building this list outï¼Œ we actually ended up with 185 different signals that we couldn't fit into one slideã€‚

 and we reallyï¼Œ really tried to kind of fit at allã€‚ but we just couldn'tã€‚

 So what we've done here is we've picked just a few that are exemplaryã€‚ And for the full listã€‚

 like we saidï¼Œ we've open source this projectã€‚ the code is thereã€‚

 So anybody that's curious can kind of go and take a peekã€‚

So the first example is the time the requests take so when you have a client application sends a request out that takes time when the server processes that responds and comes back that also takes time So we want to take these two time values and extract some statistics from themã€‚

 What's the minimumï¼Œ What's the maximumï¼Œ What's the medianï¼Œ What's the deviationã€‚

 is it always the same or do we see some strangeness thereã€‚

 The second is we want to see the time interval as wellã€‚

 so not just how long did the requests take but how long did the requests can between the requests themselves So is it always five seconds is it always 10 secondsã€‚

 is it robotic or is it more burstyï¼Œ do we see kind of more of a human using an application type of a patternã€‚

We also want to see if there are any sequences that are presentã€‚

 so do we see an application send a get request to a server and then a post request to another server over and over again and that's how it communicates or do we see it just sending a get request to one server or do we not see any sequences at all right how does this application behave on a day- to- day basisï¼Ÿ

We also want to see what are the typical HTP methods and statusesã€‚

 do we see an application only use get and post or do we see get post delete or do we see a variety of eight others so we can kind of see what the normal HP statuses and methods are to be able to kind of capture what that essence isã€‚

And then lastlyï¼Œ what are the files that are being movedï¼Œ if anyï¼Œ rightã€‚

 do we see a lot of files being uploadedï¼Œ Do we see noneï¼Œ What are the file types for these filesã€‚

 You could imagine a boxï¼Œ cloud storage app moves a different kind of file set as Spotify a music streaming service right so depending on what kind of file types they move that also matters to how the application is or how the application behavesã€‚

So once we had these 185 featuresï¼Œ the next thing we did is Colin and I looked at each other and saidã€‚

 okayï¼Œ let's give this a travelerï¼Œ let's see if this works right so we did is we picked 20 applications that we saw all across pretty much all the organizations that we saw we had some malware traffic lying around we just threw that in there as well and we set up just one random forest modelã€‚

 multiclass classification problem where each application was a classã€‚That's simple straightforwardã€‚

 Just a quick test to see if this worksã€‚ And what we found is we actually do a fairly good job of actually telling the applications apart from each otherã€‚

 even with the small dataã€‚ So on the vertical and this heat mapã€‚

 you can see on the vertical is the true value and on the horizontal is the predicted valueã€‚

 And you can see the kind of shaded blue line from the top left all the way to the bottom right that we can tell of which application is which most of the timeã€‚

 there are some instances where it's difficultï¼Œ as you can see Chrome edge and box are a little bit difficult to apart from each other and we kind of dive into why that is towards the end of the talkã€‚

 Microsoft word and Microsoft Excel are a little bit difficult to tell from each otherã€‚

 But generally we do a pretty good job of telling the applications apartã€‚

 and you can see the malware class actually like the fourth or fifth one from the topã€‚

 So we're able to tell that apart from other applications as wellã€‚

 So this gave us confidence that pursue building a detector right and we wanted this detector not onlyã€‚

ðŸ˜Šï¼ŒToJust give us predictionsã€‚ But we wanted to explain why these predictions were coming out the way they were as wellã€‚

 So those are the two big things we wanted from this detectorã€‚

So what we did is we took as much data as we couldã€‚

 as much of the 56 billion transactions as we could we instead of 5000 use 500ã€‚

000 observations per application and instead of using one random force modelã€‚

 we move to having one X boost model per application so each application would have its own model to be able to capture even better what that application is really doing So more traffic better model better setup upã€‚

And what we foundï¼Œ we just have one sample result here for the box client appã€‚

 We actually do a fairly good job of telling which observations are box and which our observations are notã€‚

 Nowï¼Œ we talked about explainabilityã€‚What exactly is the model picking upã€‚

 And to help us do this is what we have we have here is a shop plotã€‚

 We'll go over what a shop plot is in a few slidesã€‚ But hereã€‚

 what it allows us to do is see which features are important for this particular modelã€‚

 And you can see for the box modelã€‚The client bytesã€‚

 the amount of data that client application is sending to the server is importantã€‚

 The cloud storage appï¼Œ rightï¼Œ So you see the average client bytesï¼Œ the medianï¼Œ the minimumã€‚

 the maximumï¼Œ these are all importantã€‚Where that data is going is also importantã€‚

 So you see the domainsï¼Œ box netï¼Œ API docï¼Œ box do comã€‚

 those are important because that's where typically Box sends the dataã€‚

What the server responds back withï¼Œ the content type is also importantã€‚

 So we see here JSO is what the server responds back withã€‚

 So you can see all of these features are helping us kind of dive deep into how B behavesã€‚

 and because of thisï¼Œ we're able to kind of captureã€‚Like I saidï¼Œ the essenceã€‚

 the simplified of how box isã€‚And we had similar results for the other applications as wellã€‚

 so each application here had its own modelï¼Œ its own feature setã€‚

 its own set of important signals to tell how the application behavesã€‚

 we had similar performance metrics for these pretty high accuracy and true detection rate and low false positive rates for theseã€‚

So this gave us a lot of confidence to go into the next part that I'll let call into is my favorite part of the talkã€‚

 and I'll let Colin walk you through itã€‚ðŸ˜Šï¼ŒYeahï¼Œ thanks De Mollyï¼Œ so yeahï¼Œ the next phase here wasã€‚

 okay greatï¼Œ we can identify applications and profile themã€‚

 but is this useful in some way can we detect an actual threat with itï¼Ÿ

So what we did was we actually set up a red team blue team exercise internallyã€‚

 we found a red teammer who does this constantly within Netcope and he agreed to help us out so Mohanraj is our red teamer and basically what we told him was hey we're working on this project we have these apps that we're analyzing out of these common apps what we want you to do is pick one and set up a scenario where you compromise it and communicate with your own C2 server Don't tell us what application you compromisedã€‚

 don't tell us anything about your C2ã€‚Or how you're communicating nothingã€‚ Don't tell us anythingã€‚

 Just do itã€‚ And then we will see if we can find it in the network trafficã€‚

So our job was to model the common apps and then detect this communicationã€‚

So Mohan Raj ended up selecting Spotify the list of applicationsã€‚

 and he set up his command control in something called Github code spacesã€‚

 So for anyone who's not familiarï¼Œ this is just a service that GitHub runs where you can basically code in the browser and run it and they'll host it for youã€‚

 So that's where he set up his C2 serverã€‚And this is just a really simple diagram to showã€‚

 hey we have our victim machine runningï¼Œ Mohenraj infected itï¼Œ he's got Spotify runningã€‚

 it's communicating with Spotify like you would expectã€‚

 and it's also communicating with GitHub code spacesã€‚Nowã€‚

 if you're just looking at this traffic in aggregateã€‚

 it probably wouldn't raise any red flags because it's just likeï¼Œ ohã€‚

 maybe it's just developer trafficï¼Œ they're listening to music and they're using Gitthub codespace as big dealã€‚

å—¯ã€‚And in this caseï¼Œ there was a Spotify user agent that was communicating with bothã€‚Soã€‚

Just a quick sample of the victim's machineï¼Œ we could see that the client is running and it's using this server called Superduperchains Githubã€‚

 devevï¼Œ so that's the C2 URLï¼Œ and so Mohanj is running a tool thereã€‚And the attacker console hereã€‚

 So this gave him remote code execution on the victim machineã€‚ And we can see him runningã€‚

 Who am I printing the working directory and so onã€‚Soï¼Œ he's successfullyã€‚

Set this up where it's communicating back and forthã€‚And then we took the network trafficã€‚

 and we were likeï¼Œ okayï¼Œ what do we getï¼Œ Wellï¼Œ sure enoughï¼Œ our proof of concept tool hereã€‚

Showed Spotify communicating with this Github do devvã€‚

 And it found that it was an anomaly with 94% confidenceã€‚ So we were successful thereã€‚

So we went back and showed that to Mohan Rajã€‚And his reaction made us giggle like a couple of schoolgirlsã€‚

 so I had to include that hereã€‚So I'll let Dag Mai kind of take it from here to explain the explanation under the anomalyã€‚

Awesomeï¼Œ thank youï¼Œ Colã€‚Yesï¼Œ Mohan had set this upã€‚ We got the trafficã€‚

 We ran it through an early version of being we were able to detect it But what were we able to detect what exactly did this detection rely onã€‚

 So here we have a shop plot like I mentioned earlierã€‚

 So a plot just to simplify it gives you a list of features that are important for this prediction and which way they swayed did it push it more towards the anom side or push it this is a nonomal towards the blue sideã€‚

 So here you can see a list of all the features that are incremented kind pushing it more to the anom sideã€‚

 There are few that are blue that are pushing it the other wayã€‚

 And I wish we could have more time to go over each one in depthã€‚

 We want have that So we done is we picked5 that we want to quickly go over So firstã€‚

 the time taken in milliseconds is off for Sifyã€‚ This communication is not how we've seen Spotify communicate as far as the time the requests take So that kind of pushes it towards the anom sideã€‚

 The client bitesï¼Œ the sum the average and the minimum or all off Sifyã€‚

 This is the kind of data we see the clientã€‚Sending to the serverã€‚ Nowï¼Œ to Mohan's creditã€‚

 he was trying to be low and slowã€‚ So the amount of transactions that we saw were in line with how Spotify communicatesã€‚

 So you see that pushing it a little bit towards the blueã€‚ But overallã€‚

 all the other features were kind of flagging this towards the anonymousã€‚

 So even if he was trying to be low and soulï¼Œ it' still kind of showed up on our radarã€‚

 we were able to flag it anonymous with 94% confidenceã€‚ðŸ˜Šï¼ŒAnd all that calling over demoã€‚Yeahã€‚

 so with thatï¼Œ we've been showing you up until now the research leading up to this and we wanted to also show you how the tool operates todayã€‚

 so I'm going to go ahead and run a demo and this demo is available in the GitHub repo itself so what I'm running right nowã€‚

 everybody could run later on whenever they download itã€‚



![](img/d00dcf1959c47dd8a2d406fae729914c_1.png)

And basicallyï¼Œ what's included in the demo isã€‚

![](img/d00dcf1959c47dd8a2d406fae729914c_3.png)

A network traffic capture of the scenario we've been talking aboutã€‚

 So this scenario is there's a box client and all of a sudden it starts communicating with this Dgmaly do I O serverã€‚



![](img/d00dcf1959c47dd8a2d406fae729914c_5.png)

Andã€‚We have a horror fileã€‚

![](img/d00dcf1959c47dd8a2d406fae729914c_7.png)

So up the top of the screenï¼Œ hopefully you can see thisã€‚

 there is a H file that's being analyzed by beam hereï¼Œ and so it parss 300 network transactionsã€‚



![](img/d00dcf1959c47dd8a2d406fae729914c_9.png)

![](img/d00dcf1959c47dd8a2d406fae729914c_10.png)

Andã€‚Maps them to their applicationsï¼Œ and then it runs through the featuresã€‚

 runs through our detectorï¼Œ and basically saysï¼Œ heyã€‚

 there are seven applications in this network traffic captureï¼Œ and I have a model for one of themã€‚

 which is boxã€‚ So beam automatically says heyï¼Œ I have models for some of the applications I foundã€‚

 I'm going to go ahead and run my detector overã€‚

![](img/d00dcf1959c47dd8a2d406fae729914c_12.png)

![](img/d00dcf1959c47dd8a2d406fae729914c_13.png)

![](img/d00dcf1959c47dd8a2d406fae729914c_14.png)

![](img/d00dcf1959c47dd8a2d406fae729914c_15.png)

![](img/d00dcf1959c47dd8a2d406fae729914c_16.png)

So it ran the detector in this caseï¼Œ and it found a critical compromiseã€‚

 So this is where it's finding the communication with Dg Valley IOã€‚



![](img/d00dcf1959c47dd8a2d406fae729914c_18.png)

![](img/d00dcf1959c47dd8a2d406fae729914c_19.png)

And then it's just giving you the top five reasons we didn't want toï¼Œ I meanã€‚

 there's a lot of text hereï¼Œ we didn't want to add even more text with every feature and its outcomeã€‚



![](img/d00dcf1959c47dd8a2d406fae729914c_21.png)

![](img/d00dcf1959c47dd8a2d406fae729914c_22.png)

![](img/d00dcf1959c47dd8a2d406fae729914c_23.png)

To the output so it's just showing the top few indicators that contributed to the probability that this is an anomaly and so any traffic capture you run will perform the same wayã€‚

 it'll show you the first few and then if you want to see more you can look at a sha plot that gets generated on the file systemã€‚



![](img/d00dcf1959c47dd8a2d406fae729914c_25.png)

![](img/d00dcf1959c47dd8a2d406fae729914c_26.png)

![](img/d00dcf1959c47dd8a2d406fae729914c_27.png)

![](img/d00dcf1959c47dd8a2d406fae729914c_28.png)

Soã€‚With thatï¼Œ let me go back to the slidesã€‚And I'll let Do Mai walk through the Sha plot hereã€‚

 Awesomeï¼Œ thank youï¼Œ Colinï¼Œ Every time we do that demo kind of gives me a little bit of chillsã€‚

 We're going through these slides quicklyã€‚ So it's kind of fairly easy to assume that you knowã€‚

 this is how quickly the research progressã€‚ but it was notã€‚

 There is a lot of trial and error to be able to kind of get to this pointã€‚ But nonethelessã€‚

 like Colin saidï¼Œ all of this is available in Bea todayã€‚

 So if you download this to run this that par is includedã€‚

 you will get a shot plot that looks like the followingã€‚Againã€‚

 we won't have time to go through each oneã€‚ So we've picked as the top four here to kind of highlight and quickly go overã€‚

 So first is the URL entropyã€‚ So the Shannon entropy of the URL is off for how we see box typically communicateã€‚

 We see a lot more in a box URL trying to identify the fileã€‚ what chunk of the file is updatedï¼Œ etcã€‚

Second is the server byteï¼Œ so the amount of data the server returns back to the application is also offã€‚

 so that pushes it towards the anomalous sideã€‚Third is the time it takes againã€‚

Time the requests take is not in line with a box applicationã€‚

 So that flags it as anomalous a little bit as wellã€‚ And then lastlyï¼Œ this is a new oneã€‚

 is the key host namesï¼Œ soã€‚Typicallyï¼Œ when we see B communicate to serversï¼Œ to hostsã€‚

This isn't the kind of host we see it communicating toã€‚ Not only is thisã€‚

 not any of the hosts we see it communicating toï¼Œ It's not related to any of the hosts at all eitherã€‚

 So it's really far out thereã€‚ So because of thatï¼Œ this also pushes it to the anomalous side as wellã€‚

 And because of these four and many of the other reasons that you seeã€‚

 this pushes it towards the anomalous side with about 99% confidenceã€‚

So when we talk about the values that are being pushedã€‚

 I just want to highlight here that these are in log odds so when we say this is pushing it in 0ã€‚

05 Editive this wayï¼Œ that's actually increasing the odds that this is anomaly by 1ã€‚

05 x when it's pushing it by 1ã€‚7 this is actually increasing the odds that it's five that it's anomalous by 5ã€‚

47 so that's quite a noticeable increase like that's how strange it is for this feature to not be in line with the box traffic everything you've seen about box indicates that this should be how a box application communicatesã€‚

So if we go back to the introduction that Colin didã€‚

We said we wanted to build a detector that would flag something like the followingã€‚

 Communication to this domain is anomalousï¼Œ with very high confidenceã€‚

And we wanted the explainability behind itã€‚ Why is it that it's anomalousï¼Œ Wellã€‚

 the URL randomness is offã€‚ This isn't how we see the URLs for this particular applicationã€‚

 So this increases the odds that this is an anomaly by 5 xã€‚

The host that this's communicating to is not in lineã€‚ Not only is it not a typical hostã€‚

 but it's not related to any host that we know of as wellã€‚ So that increases the odds by 4 xã€‚Againã€‚

 the path depthï¼Œ the information we see in the pastã€‚

 the resources that are being hit aren't in line with this application as wellã€‚

 similar to the URL of randomnessã€‚ So this increases the odds that this is anomaly by 3 xã€‚

 So because of these and many other reasonsï¼Œ we're going flag this as anomalous communicationã€‚

And I'll hand it over to Colin to talk about how you can use this for your own models as wellã€‚Yeahã€‚

 so you all might beã€‚Watching is thinking that's great that you guys can do all this with eight applicationsã€‚

 but what about the rest of the applications I runï¼Ÿ

And what we wanted to do was address some of that concern and include in beamM the ability to add more models so you can add custom or bespoke models to the portfolio that's running within beamM and all you need is network traffic captureã€‚

 so PAP files and H files are primarily what beamM will take as inputã€‚

And so we do have an unsupervised ML component that will take those traffic capturesã€‚

 and it'll look for any non browser application and model thatã€‚And soã€‚

If you're curious about what the unsupervised models look likeï¼Œ actuallyï¼Œ before I go to thatã€‚

 I wanted to also mention thatã€‚Like anything else with machine learningï¼Œ more data is betterã€‚

 we do have a threshold of at least 100 transactions for any applicationã€‚

 So if you have a traffic capture and you want to train a new modelã€‚

 you need to have at least 100 transactions in thereã€‚And if you don'tï¼Œ it'll find the applicationã€‚

 but it'll say I'm not generating a modelã€‚So the unsupervised trainingï¼Œ what does that look likeã€‚

 wellï¼Œ it's an ensemble and it consists of isolation forestï¼Œ one class SVMï¼Œ and an auto encoderã€‚

And so these three contribute toã€‚Being able to find anomalies within the network traffic that you're feeding itã€‚

 So it's slightly different than what we've done at Netcope offlineï¼Œ but this was our first versionã€‚

 our best effort of making it available to you todayã€‚Soã€‚With thatã€‚

 I wanted to walk you through another scenario hereã€‚Let's say I wanted to create a model for notionã€‚

 So I created a Windows clientã€‚ I have a Windows machine runningã€‚

 I download the notion client and proxymanã€‚And proxy man just allows us to capture the trafficã€‚

So I set up the client and set up proxymen and then run it and it's communicating with notion capturing that trafficã€‚

 so that generated a hard file for usã€‚And now what I do is I give that ha file to beam as input and tell it to createã€‚

 I tell it to train on that inputã€‚And it goes ahead and creates a new model for meã€‚

 So this is kind of what it would look likeã€‚And another noteã€‚ So like I mentionedã€‚

 we have a threshold of a minimum number of transactionsï¼Œ soã€‚Not only was notionion runningã€‚

 but also VS code was runningï¼Œ but it didn't have enough traffic to create a model for itã€‚

So we only have the notion model and then up until now we've also been demoing these compromisesã€‚

 so I wanted to show you what does it look like if there is no compromiseã€‚

And this is basically what it would look likeã€‚ So what I did was I created a new model for notion with a ha fileã€‚

 and then I reused that same ha file and ran it through the detectorã€‚

And so it didn't detect any anomalies in this caseï¼Œ everything looked goodã€‚And so with thatã€‚

 I'll hand it back to Dg Maui to talk about next stepsã€‚Awesomeã€‚Think goneã€‚ So every time weã€‚

Did a travel and did a testã€‚ And we saw when something successful happenã€‚

 There were like two or three other things that came out of it like that we need to improveã€‚

 We need to make betterã€‚ right So we tried againï¼Œ we would want to go over all of theseã€‚

 We just don't have the timeã€‚ So we picked our three that are top of mind for usã€‚

 These are things we're still working onã€‚ We're still thinking about we actually having conversations about some of these yesterdayã€‚

 So if you guys are interestedã€‚ or if you have a new clever way of working through any of these challengesã€‚

 Please collaborate with usã€‚ this is an open source project as of todayã€‚

 So it's definitely all of this is availableã€‚ First what we call high entropy applicationsã€‚

 like I mentionedï¼Œ the eight that we have hereã€‚ we do really well detecting anomalies forã€‚

 but there are certain applicationsã€‚ for exampleï¼Œ browsers or it's quite difficultã€‚

 And it's difficult because we can't really capture their essence or profile across multiple devicesã€‚

 Everyone uses their browser very differentlyã€‚ So it's very difficult to kind of come up with a feature set to capture all of theseã€‚

 So one of the things we're thinking about is maybe using a different featureã€‚

Set for them or maybe even a different strategy altogether for these sort of applicationsã€‚

Second is additional methods of attributionã€‚ So we're using the user agent strings hereã€‚

 and 99 plus percent of the time no one changes itã€‚ it's very reliableï¼Œ but like Colin mentionedã€‚

 attackers can change thisã€‚ sometimes it's set to knowll and in these casesã€‚

 we want to be able to maybe hook into endpoint information like the process or process to be able to use as additional source of attribution for this trafficã€‚

 and then lastly is further support for bespoke modelã€‚

 So they Colin mentioned we do a pretty good job already of kind of building models for your bespoke applicationsã€‚

 but there's definitely room for improvement hereï¼Œ maybe coming up with a new model to add to the ensemble or maybe coming up with a new ensemble altogetherã€‚

 So if these are this or any of the other two points are interesting to you guys definitely reach out to us and let us know and I'll hand it over to Colin to talk about where you can do thatã€‚

Yeahï¼Œ thanksã€‚Here you'll see the QR codeï¼Œ which will link you to our GiHub repo and the URL is also down thereã€‚

 so this will be available in the slides that they send outã€‚

 but if you guys want to look at it todayï¼Œ feel freeã€‚So what are the takeaways hereï¼ŸWellã€‚

 first of allï¼Œ we just wanted to make sure everybody here kind of left with this idea that supply chain compromises are too terrifying to leave to one type of solutionã€‚

 the whole motivation behind this wasï¼ŒWe needï¼Œ different solutions in different spots in order to really address and mitigate against something like solar ones happening againã€‚

The next thing is that if you're interested in beamMã€‚

 it will detect anomalies solely from web trafficï¼Œ beamm is not a proxyï¼Œ so it's out of bandã€‚

 it's out of the critical pathï¼Œ but you can feed it network traffic captures and get some resultsã€‚

It also does not decrypt the data itself in any way that's sort of outside the scope of the projectã€‚

And then lastlyï¼Œ you can add new models for the applications that you run in your own environmentsã€‚

Soã€‚Yeahï¼Œ that's about itã€‚ So thank you very much again for your time and please let us know if you have any questionsã€‚

 We have like another minute and a half or soï¼Œ if anybody wants to come up to the micã€‚

 we'd be happy to take any questionsã€‚Yeahï¼Œ go aheadã€‚ This is super coolã€‚ Thanksã€‚

 Do you think it would be possible to implement in an EDR instead of on theã€‚I'm sorryã€‚

 I didn't catch all of thatã€‚ Could you say that againã€‚

 Do you think it would be possible to implement this at EDR level instead of on the networkã€‚

 I'm assuming you're doing it at sort ofã€‚InDã€‚Yesï¼Œ yesã€‚

We didn't look at integrating with any particular EDRsï¼Œ but like Dg Maui mentioned for next stepsã€‚

 I think we're very interested in seeing what other data we might be able to integrate withã€‚

 so even if it's not sitting on every endpoint like deployed somewhere being out of band and taking data from EDR would probably be something we're interested in doingã€‚

To actually his related to his question I was thinking that I could use EDR telemetry data in order to feed like by the process all the network activity in order to use the modeling so my question is how easy is would it be toã€‚

New input types to the beam modellaã€‚New in typesã€‚ So if I can get EDR telemetry to tell me Yeahã€‚

 by processï¼Œ requests are being madeã€‚ I'm going to get that additional signals as wellã€‚

 you mean Yeahï¼Œ and that we I have to profile it based on the processã€‚ And to his pointã€‚

I could then use a mechanism to monitor each process to see what that did rather than by user agent stringã€‚

 but by the process I on the host sideã€‚ðŸ˜”ï¼ŒYeahï¼Œ so it's not natively supportedã€‚

 but there's no control in place that's keeping you from adding your own signalsã€‚

 like we said this is all code that's available so you can easily extend it as wellã€‚

 that's actually a really good idea for us to kind of maybe support additional features as well that is a next step like Col mentioned to be able to support endpoint information as wellã€‚

 Nothings like to summarize nothing stopping you from adding itã€‚

 It's just not something we support demo if you want to go in that direction can useã€‚ç¬¬å•Šã€‚

Event telemetry mechanism TW in Windows to do that rather than relying on a specificã€‚å—¯ã€‚åˆ˜æµ·ã€‚Sorryã€‚

 there is one moreã€‚Go aheadã€‚Packet headers orã€‚Was in the dataã€‚I'm sorryï¼Œ can you just say that againã€‚

 was all the data he did hereï¼Œ was it all encrypted or was he all worked off just packet headers or did you do something differentï¼Ÿ

Yeah they're not encrypted basicallyï¼Œ this is like assuming you've already sort of proxed the trafficã€‚

 decrypted itï¼Œ and you could use a PCAP file or a H file as inputã€‚So you didn't do anything withã€‚

can capture like from an NDRã€‚Solution from a network Pro responseã€‚we've done some packet capturesã€‚

 but againï¼Œ like we said it was decrypted trafficã€‚ So is HP traffic in the packet captures mostlyã€‚

 yeahã€‚Thank youï¼ŒThe way the bin actually works right now it's an offline productã€‚

 so you analyze one pickup at a timeï¼Œ It's not like you can runã€‚An instanceï¼Œ and get bigã€‚

Live data from all your endpoints and analyze them live and then integrate it with V or something thatã€‚

Just one pickup at a timeï¼Œ from one single point at a timeã€‚So yeahï¼Œ go aheadã€‚ Noï¼Œ go aheadã€‚ So it'sã€‚

 it's not just one P at timeã€‚ You can run it against multipleã€‚ It does support multipleã€‚

 but it's not asã€‚It's not at the stage of where you're thinking of you can deploy itã€‚

 And it's kind of a full flash system just yetã€‚ Noï¼Œ I don't have calling you an a inã€‚5 featuresã€‚

Sorryï¼Œ is there any documentation in your Github which talks about these 185 features it'sã€‚

 it's yeahï¼Œ it's in the repoã€‚ Yeahï¼Œ it's in the repoã€‚ there should be a Python fileã€‚ If youã€‚

 if you already have it upã€‚ if you come up by we can show you exactly where it isã€‚

 there should be a Python file that shows youï¼Œ yeahã€‚I think it is usefulã€‚ I meanï¼Œ maybe we couldã€‚æ²¡æœ‰ã€‚

Okayï¼Œ I think that's our timeï¼Œ so thank youã€‚ Thank you allã€‚Thank youã€‚

