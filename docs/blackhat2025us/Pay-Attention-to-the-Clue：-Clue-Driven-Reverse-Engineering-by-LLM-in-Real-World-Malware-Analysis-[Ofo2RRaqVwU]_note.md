# 课程 01：关注线索：LLM在真实世界恶意软件分析中的线索驱动逆向工程 🕵️♂️

在本节课中，我们将学习如何利用大型语言模型进行稳健且可靠的恶意软件逆向工程。我们将介绍一种名为“线索驱动”的方法，该方法通过检测LLM的“幻觉”来确保分析结果的准确性，并构建一个自动化分析系统。

---

## 引言：逆向工程的挑战与LLM的幻觉

![](img/998aaedef1ad9ec59ac6130c632d5a7b_1.png)

大家好。在演讲开始前，我有一个问题。请举手示意，如果你热爱逆向工程，特别是恶意软件分析。看来有很多人。但似乎也有很多人没有举手。这意味着你不喜欢逆向工程。你讨厌逆向工程。这没关系。我也讨厌逆向工程。我认为你们来对了地方，因为今天我将展示如何构建一个没有逆向工程痛苦的世界。

![](img/998aaedef1ad9ec59ac6130c632d5a7b_3.png)

今天，我们的演讲主题是“关注线索”。我们将介绍如何让语言模型能够非常稳健和可靠地进行逆向工程。

![](img/998aaedef1ad9ec59ac6130c632d5a7b_5.png)

现在，让我介绍一下自己。我叫谭驰，是Scraft公司的研究团队负责人。Scraft是一家专注于网络安全的人工智能公司。我的研究重点集中在人工智能和语言模型上。

![](img/998aaedef1ad9ec59ac6130c632d5a7b_1.png)

这是我的联合演讲者，魏杰。他是一名高级网络安全研究员，也是恶意软件分析专家。实际上，今天我们将介绍的系统，是我试图通过语言模型克隆另一个魏杰。

![](img/998aaedef1ad9ec59ac6130c632d5a7b_3.png)

第三位贡献者是赵明。他是一名网络安全研究员，同样专注于恶意软件分析和二进制自动化分析。

![](img/998aaedef1ad9ec59ac6130c632d5a7b_7.png)

![](img/998aaedef1ad9ec59ac6130c632d5a7b_5.png)

让我们开始吧。在演讲开始时，我想让每个人都真正理解语言模型面临什么样的挑战。我需要大家为我做点事。请假装你是语言模型两分钟。

这是系统提示：请扮演一名专业的恶意软件逆向工程师，尝试重命名变量 V1。现在，是时候生成答案了。请告诉我你的答案，如果你认为是 A、B、C 或 D。

看来很多人都认为答案是 C。让我们看看。正确，很好。

![](img/998aaedef1ad9ec59ac6130c632d5a7b_9.png)

![](img/998aaedef1ad9ec59ac6130c632d5a7b_10.png)

![](img/998aaedef1ad9ec59ac6130c632d5a7b_11.png)

![](img/998aaedef1ad9ec59ac6130c632d5a7b_12.png)

接下来是第二轮。请重命名变量 V3。请举手示意，如果你认为答案是 A、B、C 或 D。看来有些人认为是 C，有些人认为是 D。让我们看看。哦，答案不是它们中的任何一个。正确的答案是不要举手。

我们很容易忘记，当我们面对我给出的提示时，我们总是有选择权。这对于语言模型来说也是如此，它倾向于生成最可能的答案，也更容易犯这种错误。

接下来，我们将看看为什么“面积”不是正确答案，以及这种错误会带来什么影响。

![](img/998aaedef1ad9ec59ac6130c632d5a7b_14.png)

![](img/998aaedef1ad9ec59ac6130c632d5a7b_7.png)

![](img/998aaedef1ad9ec59ac6130c632d5a7b_16.png)

首先，我们可以看到这个代码块。这是语言模型的输出。它看起来非常合理，将 V3 重命名为“面积”。但当我们深入研究 `sub_` 函数时，我们可以看到，它实际上不是计算面积，而是检查面积。语言模型不知道这一点，没有这个上下文。它试图生成答案，并在重命名局部变量 V3 时出现了一些错误。

![](img/998aaedef1ad9ec59ac6130c632d5a7b_18.png)

这种错误不会在这里停止。它开始传播到 `then` 函数，然后 `then` 函数也传播到 `color` 函数，`color` 函数给出了错误的结果。我们可以看到，这个单一的错误，就像一个滚雪球，变得越来越大，直到我们对整个程序产生完全误解。

![](img/998aaedef1ad9ec59ac6130c632d5a7b_20.png)

那么，什么样的语言模型会犯这种错误呢？

![](img/998aaedef1ad9ec59ac6130c632d5a7b_9.png)
![](img/998aaedef1ad9ec59ac6130c632d5a7b_10.png)
![](img/998aaedef1ad9ec59ac6130c632d5a7b_11.png)
![](img/998aaedef1ad9ec59ac6130c632d5a7b_12.png)

你可以看到，所有最先进的 R 语言模型都没有拒绝回答问题。它们都认为 V3 是结果面积。基于此，它们导致了我刚才提出的问题中的错误。

这种错误在恶意分析场景中尤其危险，因为我们没有恶意软件的“基本事实”。恶意软件作者不会告诉我们我们的理解是否正确。因此，人类需要花费大量时间和精力来验证语言模型得到的结果。这会让我们更难提前下班。

![](img/998aaedef1ad9ec59ac6130c632d5a7b_22.png)

![](img/998aaedef1ad9ec59ac6130c632d5a7b_14.png)

为了让语言模型成为我们的好伙伴，让我们能够提前下班，我们需要知道它何时在“幻觉”，何时在“撒谎”。

这就成了我们需要解决的快速问题。

---

![](img/998aaedef1ad9ec59ac6130c632d5a7b_24.png)

## 现有策略的局限性

![](img/998aaedef1ad9ec59ac6130c632d5a7b_16.png)

根据 OpenAI 的优化指南，有两个主要策略：语言模型优化和上下文优化。大多数与逆向工程相关的主题都集中在这两种策略上，但这两种策略无法修复“幻觉”问题，因为它们都是单一来源信任。

![](img/998aaedef1ad9ec59ac6130c632d5a7b_26.png)

![](img/998aaedef1ad9ec59ac6130c632d5a7b_18.png)

单一来源信任的问题是，我们不能盲目信任语言模型的输出，即使它声称有很高的置信度。那么我们如何知道语言模型是否处于“幻觉”状态呢？我们需要退回到人类场景。

![](img/998aaedef1ad9ec59ac6130c632d5a7b_28.png)

---

## 灵感来源：人类调查策略

![](img/998aaedef1ad9ec59ac6130c632d5a7b_20.png)

![](img/998aaedef1ad9ec59ac6130c632d5a7b_30.png)

即使没有人被 FBI 逮捕或调查过，我想大家都看过一些关于 FBI 的电影。大家都知道，FBI 有两种主要策略来判断某人是否在撒谎。

第一种是“参考检查”。通过参考检查，我们不只是信任单一来源。我们会去收集证据和外部线索，把它们放在一起，看看故事是否一致。

对于“测谎仪”，调查人员会在询问某人时监控信号，比如压力或心率，以判断某人是否在撒谎。这两种策略都非常有用。

![](img/998aaedef1ad9ec59ac6130c632d5a7b_32.png)

接下来，我们将看看如何将这种策略引入语言模型领域。

---

## 方法一：参考检查——利用注意力机制

![](img/998aaedef1ad9ec59ac6130c632d5a7b_22.png)

![](img/998aaedef1ad9ec59ac6130c632d5a7b_34.png)

在我们深入之前，这是现代语言模型 Transformer 的架构。其中有一种称为“注意力”的机制。这就是我们如何进行参考检查。接下来，我们使用 softmax 来进行测谎。我们将重点介绍这两种不同的方法。

首先，让我们看看参考检查是如何进行的。

在参考检查中，我们需要知道什么是注意力。注意力是语言模型内部的一种机制，帮助语言模型知道它需要关注哪些标记。在现代语言模型中，有多个层，每层有多个注意力头。因此，有几十种不同的注意力头。

![](img/998aaedef1ad9ec59ac6130c632d5a7b_36.png)

![](img/998aaedef1ad9ec59ac6130c632d5a7b_38.png)

有些注意力头执行类似句法的功能。它们关注语法和结构。

![](img/998aaedef1ad9ec59ac6130c632d5a7b_40.png)

![](img/998aaedef1ad9ec59ac6130c632d5a7b_24.png)

![](img/998aaedef1ad9ec59ac6130c632d5a7b_42.png)

有些可能像这样。它是一个代词，所以它会关注它代表什么。而“past”是动词，所以它会关注宾语和主语。还有其他类型的注意力头，比如更高级的句法头。其中一个句法头可能关注推理。它会发现“harder”关注“past”，因为“past”是测试未通过的原因。

是的，有很多不同类型的注意力头。但我们感兴趣的注意力头是，它能告诉我们模型在生成答案时关注了哪些信息。我们希望找到这种注意力头。如果这种注意力头存在的话。

![](img/998aaedef1ad9ec59ac6130c632d5a7b_26.png)

让我们考虑一下这篇来自顶级 AI 会议的论文。在这篇论文中，他们使用复制和粘贴操作来找到一种称为“检索头”的注意力头。这种注意力头会在执行复制和粘贴时，检索它想要复制的标记。

但今天，我们不是在做复制和粘贴。我们是在重命名变量。所以我们需要找到另一种注意力头。我们称之为“线索焦点注意力头”。以下是我们如何找到线索焦点注意力头。

![](img/998aaedef1ad9ec59ac6130c632d5a7b_44.png)

![](img/998aaedef1ad9ec59ac6130c632d5a7b_28.png)

![](img/998aaedef1ad9ec59ac6130c632d5a7b_46.png)

首先，我们需要识别高信息量的线索。接下来，我们将执行我们的任务。记住，我们的任务是重命名变量和函数名。第三，在我们完成重命名任务后，我们还会查看模型内部的注意力，提取注意力，看看这个注意力头关注了什么。如果它关注我们在第一步中识别的线索，我们就给它高分。如果没有，我们就给它低分。通过这种方式，我们可以对它们进行排序和排名，得到一组线索焦点注意力头。

接下来，让我们看看我们的一个线索焦点注意力头是如何工作的。

![](img/998aaedef1ad9ec59ac6130c632d5a7b_48.png)

![](img/998aaedef1ad9ec59ac6130c632d5a7b_30.png)

我们可以看到，我们期望在这里可视化一个线索焦点注意力。我们发现，当我们输入代码时，右侧是生成的输出。在它生成 V1 的答案之前，它高度关注“width”。同样，对于 V2，当它输出 V2 的答案时，它也高度关注“height”。这种注意力集中在高信息量的线索上。

但是当我们上传 V3 时，我们可以看到 V3 没有高信息量的线索。所以它关注了一些随机的、不可用的东西。我们可以看到 V3 的答案不是基于某些信息线索，所以我们可以拒绝 V3，因为 V3 不可信。

![](img/998aaedef1ad9ec59ac6130c632d5a7b_50.png)

![](img/998aaedef1ad9ec59ac6130c632d5a7b_32.png)

此外，我们还对线索焦点注意力头在语言模型中的重要性感兴趣。所以我们进行了一项消融实验。在这个实验中，我们将关闭一些注意力头，并监控它对语言模型输出的影响。绿色表示输出正确，红色表示输出不正确。

![](img/998aaedef1ad9ec59ac6130c632d5a7b_52.png)

我们可以看到，当我们随机关闭一些注意力头时，对语言模型的影响不大。但当我们关闭线索焦点注意力头时，它对语言模型输出的影响非常大。因此，我们可以知道线索焦点注意力头对语言模型非常重要。

在介绍了第一种方法——参考检查（利用注意力机制了解模型生成答案时关注的信息）之后，接下来我们将讨论测谎仪，即如何使用 softmax 层进行测谎。

![](img/998aaedef1ad9ec59ac6130c632d5a7b_54.png)

![](img/998aaedef1ad9ec59ac6130c632d5a7b_56.png)

---

![](img/998aaedef1ad9ec59ac6130c632d5a7b_58.png)

## 方法二：测谎仪——利用Softmax概率分布

![](img/998aaedef1ad9ec59ac6130c632d5a7b_34.png)

在 softmax 层，会有一个标记概率分布。我们可以看到，如果分布集中在一个标记上，这意味着答案可能只有一个。就像我们看到的例子，V1 的答案可能只有“width”。但是，当分布分散在不同的标记上时，这意味着答案可能是“area”，也可能是“result”。就像大家举手一样，有人认为“area”，有人认为“result”。语言模型也处于低置信度状态，对此感到困惑。这意味着我们可以知道它处于低置信度状态，并可以拒绝它的重命名。这就是我们的测谎仪。

![](img/998aaedef1ad9ec59ac6130c632d5a7b_60.png)

![](img/998aaedef1ad9ec59ac6130c632d5a7b_36.png)

至此，我们已经介绍了检测语言模型何时处于“幻觉”状态的两种主要方法。第一种是参考检查，第二种是测谎仪。

![](img/998aaedef1ad9ec59ac6130c632d5a7b_62.png)

---

## 构建自动化系统：Celebi

![](img/998aaedef1ad9ec59ac6130c632d5a7b_38.png)

![](img/998aaedef1ad9ec59ac6130c632d5a7b_64.png)

现在，让我们把这两样东西放到我们的自动化工作流中。这就是我们要介绍的系统。

![](img/998aaedef1ad9ec59ac6130c632d5a7b_66.png)

![](img/998aaedef1ad9ec59ac6130c632d5a7b_40.png)

现在，让我介绍一下我们的系统，Celebi。这个系统的灵感来自宝可梦 Celebi。就像 Celebi 可以逆转时间一样，我们期望我们的系统能够将混淆的代码逆转回人类可读的源代码。

![](img/998aaedef1ad9ec59ac6130c632d5a7b_68.png)

![](img/998aaedef1ad9ec59ac6130c632d5a7b_42.png)

![](img/998aaedef1ad9ec59ac6130c632d5a7b_70.png)

这是我们的分析流程。首先，输入是来自 IDA Pro 的反编译函数。第一步是预处理步骤。在这个步骤中，不涉及语言模型。我们将使用一些静态分析工具为我们生成线索。这些线索对后续步骤至关重要。

![](img/998aaedef1ad9ec59ac6130c632d5a7b_72.png)

![](img/998aaedef1ad9ec59ac6130c632d5a7b_73.png)

在第二步中，一旦我们有了这些线索，我们就可以使用我们的线索驱动策略来帮助我们决定需要先分析哪些函数。我们将对这些函数进行优先级排序和排序。我们知道我们想先分析哪个函数。

接下来，一旦我们知道要分析哪个函数，我们将要求语言模型帮助我们重写这些函数。我们将要求语言模型帮助我们重命名变量和函数名，并给出摘要。

![](img/998aaedef1ad9ec59ac6130c632d5a7b_75.png)

一旦我们有了语言模型的输出，在最后一步，我们不会盲目信任结果。我们将使用前面提到的方法——测谎仪和参考检查——来评估结果。我们将拒绝那些低质量的重命名。最后，高质量的重命名本身也是新的线索。所以我们将更新我们的线索集，然后调整语义，最后重复这个过程。

---

## 案例研究：分析真实恶意软件

![](img/998aaedef1ad9ec59ac6130c632d5a7b_77.png)

![](img/998aaedef1ad9ec59ac6130c632d5a7b_44.png)

现在，让我通过一个案例研究来看看我们的系统如何对抗真实的恶意软件。

![](img/998aaedef1ad9ec59ac6130c632d5a7b_46.png)

![](img/998aaedef1ad9ec59ac6130c632d5a7b_79.png)

这个恶意软件来自中国 APT 41 组织。该恶意软件的核心技术是进程注入，注入到一个 EDR 进程中。这里有两个关键挑战。首先，这个恶意软件有超过 800 个函数，并且函数名被剥离了。所以有很多函数。其次，这个恶意软件有很多 Windows API 混淆，这些 API 只在运行时解析。

![](img/998aaedef1ad9ec59ac6130c632d5a7b_81.png)

面对这些挑战，如果我们手动进行逆向工程，这将非常耗时且困难。

### 步骤一：线索提取与标注

![](img/998aaedef1ad9ec59ac6130c632d5a7b_83.png)

![](img/998aaedef1ad9ec59ac6130c632d5a7b_48.png)

让我们看看我们的系统是如何工作的。第一步，我们将看看我们在这里定义了哪些线索，以及我们如何生成这些线索。

我们将线索分为两种类型。第一种是内部线索，第二种是外部线索。对于内部线索，我们会高亮反编译函数中的模式，例如可疑字符串或可疑 API。这些线索对后续步骤有帮助。对于外部线索，我们会运行一些静态分析工具，比如仿真工具，尝试解析 Windows API 混淆。我们会在代码后面标记正确的 API。

![](img/998aaedef1ad9ec59ac6130c632d5a7b_85.png)

其次，我们还会找到一些加密常量，比如 AES S-box 或其他如 SHA-1 函数，并在代码后面标记正确的算法名称。

![](img/998aaedef1ad9ec59ac6130c632d5a7b_50.png)

![](img/998aaedef1ad9ec59ac6130c632d5a7b_87.png)

例如，在这个恶意软件中，我们看到在第一行，我们的系统可以识别出像 `agent.exe` 这样的模式。在我们识别出这个模式后，我们的系统会在代码后面添加注释，添加一个可疑字符串。这样语言模型就能看到这里有些情况。

![](img/998aaedef1ad9ec59ac6130c632d5a7b_89.png)

![](img/998aaedef1ad9ec59ac6130c632d5a7b_52.png)

![](img/998aaedef1ad9ec59ac6130c632d5a7b_91.png)

其次，对于接下来的几行，我们看到这里有一个 Windows API 调用，这个 API 被混淆了。所以在静态分析中，你看不到调用了哪个 API。但我们使用一些仿真工具，比如 CBEasy，来帮助我们解决这个问题，我们会在后面添加正确的 API 名称。例如，这里工具帮助我们添加了注释，如 `OpenProcess`，这样语言模型就能清楚地看到这个 API 是调用 `OpenProcess` 的。

![](img/998aaedef1ad9ec59ac6130c632d5a7b_93.png)

![](img/998aaedef1ad9ec59ac6130c632d5a7b_94.png)

![](img/998aaedef1ad9ec59ac6130c632d5a7b_95.png)

### 步骤二：线索驱动的规划器

![](img/998aaedef1ad9ec59ac6130c632d5a7b_54.png)

现在，我们有了线索。在第二步，我们将看看我们的规划器是如何工作的。

![](img/998aaedef1ad9ec59ac6130c632d5a7b_97.png)

![](img/998aaedef1ad9ec59ac6130c632d5a7b_56.png)

![](img/998aaedef1ad9ec59ac6130c632d5a7b_99.png)

我们想要逆向整个二进制文件，而不仅仅是单个函数。因为这个恶意软件有超过 800 个函数。有很多函数，我们不知道从哪里开始，先看哪个函数。

![](img/998aaedef1ad9ec59ac6130c632d5a7b_58.png)

如果你手动操作，过程会像这样：你会在函数中四处查看，看看哪个函数重要。最终，一旦你找到重要的函数，它们可能对你隐藏，不是因为它们是恶意的，而是因为它们被混淆了。

但好消息是，我们有线索。例如，在这里，你可以看到 `2.9B` 函数比其他函数有更多的线索。例如，`agent.exe`、`OpenProcess`、`VirtualAllocEx`，这些都是这个函数中的线索。显然，这个函数是我们分析的一个良好起点。

![](img/998aaedef1ad9ec59ac6130c632d5a7b_101.png)

![](img/998aaedef1ad9ec59ac6130c632d5a7b_102.png)

![](img/998aaedef1ad9ec59ac6130c632d5a7b_60.png)

但我们如何量化这种行为？我们如何量化哪个函数比其他函数更重要？这里我们使用一个启发式评分函数来帮助我们计算分数。例如，第一行，可疑字符串会给 1 分。而 `OpenProcess` 会给 3 分。不同的线索有不同的重要性分数。最终，我们会得到这个函数的最终分数。例如，这里是 7.5。

![](img/998aaedef1ad9ec59ac6130c632d5a7b_62.png)

![](img/998aaedef1ad9ec59ac6130c632d5a7b_104.png)

一旦我们为每个函数计算了分数，我们就可以生成一个热图。这个热图可以帮助语言模型清楚地看到哪个函数重要。比如这里的 `2.9B` 函数是 7.5 分，非常重要。

![](img/998aaedef1ad9ec59ac6130c632d5a7b_106.png)

但我们不只是先分析分数最高的函数。热图还会向语言模型提供已分析函数的历史记录。基于上下文，语言模型代理可以选择它想要分析哪个函数。例如，在分析了 `inject_code` 之后，它可能想分析 `DLLMain`，因为 `DLLMain` 调用了 `inject_code`，代理可能想看看它是如何调用的。

![](img/998aaedef1ad9ec59ac6130c632d5a7b_64.png)

一旦我们分析了一个函数，被分析的函数也会成为强大的新线索。例如，这里的 `inject_code` 调用，在我们分析了 `DLLMain` 之后，我们会看到这个 `inject_code` 调用也是一个新线索。这样在某个时刻，你就知道 `DLLMain` 在做一些注入行为。所以我们会调整父函数的分数，并将这个线索传播给父函数。

![](img/998aaedef1ad9ec59ac6130c632d5a7b_66.png)

最后，我们会为分析设置一个阈值，这样我们不会分析每一个函数。我们只分析选定的重要函数。这样，我们就不分析那些我们不关心的库函数或工具函数。我们只分析选定的函数，就能得到这个恶意软件的整体行为。这可以帮助我们节省标记，运行得更快。

![](img/998aaedef1ad9ec59ac6130c632d5a7b_108.png)

### 步骤三：LLM重写与验证

![](img/998aaedef1ad9ec59ac6130c632d5a7b_110.png)

![](img/998aaedef1ad9ec59ac6130c632d5a7b_68.png)

![](img/998aaedef1ad9ec59ac6130c632d5a7b_112.png)

现在，我们知道了我们的线索驱动策略是如何工作的。在第三步，我们将要求语言模型帮助我们重写这些函数。

![](img/998aaedef1ad9ec59ac6130c632d5a7b_70.png)

总共有三个任务我们希望语言模型完成。第一，我们希望它重命名变量。第二，我们希望语言模型帮助我们重命名函数。最后，我们会要求语言模型给出关于这些函数的整体摘要。

![](img/998aaedef1ad9ec59ac6130c632d5a7b_114.png)

![](img/998aaedef1ad9ec59ac6130c632d5a7b_72.png)
![](img/998aaedef1ad9ec59ac6130c632d5a7b_73.png)

在这个步骤之后