# 课程 P24：025 - 图神经网络模型与数据安全评估 🛡️

![](img/00f924c1e3c11236601f4993b56d9034_0.png)

在本课程中，我们将学习如何评估图神经网络模型的安全态势。我们将探讨针对图神经网络的四种主要攻击方式，并分析其原理、影响及潜在的防御策略。图神经网络已广泛应用于社交网络、推荐系统、药物发现等领域，但其安全性同样面临严峻挑战。

![](img/00f924c1e3c11236601f4993b56d9034_2.png)

## 图神经网络简介与应用 🌐

上一节我们介绍了课程概述，本节中我们来看看图神经网络的基础知识及其广泛应用。

![](img/00f924c1e3c11236601f4993b56d9034_4.png)

![](img/00f924c1e3c11236601f4993b56d9034_6.png)

图是一种无处不在的数据结构，它可以表示任意大小和复杂度的关系。例如：
*   社交网络图
*   知识图谱
*   用户-商品交互图
*   分子结构图

![](img/00f924c1e3c11236601f4993b56d9034_8.png)

图神经网络于2014年被提出，其核心目标是将非欧几里得结构的图数据映射到欧几里得空间，转换为计算机易于处理的向量。这一过程主要依赖于**消息传递**技术，即通过递归方式聚合邻居节点的信息。不同的聚合器产生了不同的模型变体，例如**图卷积网络**或**图同构网络**。

一旦节点被映射为向量（即节点嵌入），就可以进行节点分类、链接预测等任务。若进一步将整张图压缩为一个向量（即图嵌入），则可以在图级别进行图分类、图匹配或毒性预测等任务。

目前，谷歌、推特等大型公司都在后端广泛使用图神经网络来支持日常应用，这意味着其安全风险可能潜藏在众多服务之中。

## 图神经网络：新的攻击面？ ⚠️

上一节我们了解了图神经网络的基础，本节中我们来看看它为何可能成为一个新的攻击面。

随着人工智能模型在各领域的成功，其自身的安全性也受到关注。图神经网络模型及其处理的数据可能成为对手的攻击目标。接下来，我们将详细探讨四种针对图神经网络的攻击。

### 链接重识别攻击

本次攻击的目标是识别图中两个节点之间是否存在链接。攻击场景设定在节点分类任务中。攻击者能够侵入存储图神经网络模型输出的后验概率分数的数据库。

以下是攻击的具体步骤：
1.  **场景**：攻击者获取了一个大型社交网络经图神经网络处理后所有节点的后验概率分数。
2.  **简单方法**：攻击者可以直接计算两个节点后验分数向量的相似度。若相似度超过某个阈值，则推断两节点间存在链接。
3.  **进阶方法**：攻击者利用获取的后验分数，在本地使用影子数据集训练一个影子图神经网络模型。然后，他们使用该影子模型生成的数据，训练一个多层感知机作为攻击模型，以更准确地判断链接是否存在。
4.  **输入统一**：当目标模型与影子模型的输出维度不一致时，攻击者可以通过定义距离函数或计算熵差等方式统一输入，确保攻击模型有效。

值得注意的是，攻击者用于训练影子模型的数据集可以与目标模型的数据集不同，这种跨域攻击仍然可能成功。

### 属性推理与子图推理攻击

上一节我们讨论了针对节点后验分数的攻击，本节中我们来看看如果攻击者获得了图嵌入向量，能发起何种攻击。

当攻击者获得了表示整张图的嵌入向量后，可以发起两种攻击：属性推理攻击和子图推理攻击。

**属性推理攻击**：攻击者旨在从图嵌入中推断出图的基本属性（例如，图中大约有多少个节点）。
*   **方法**：攻击者首先需要拥有一组辅助图，通过查询目标模型获得其图嵌入。接着，他们在本地训练一个攻击模型（如MLP），该模型学习从图嵌入到图属性（如节点数量范围）的映射。最后，将窃取的图嵌入输入该模型，即可估计原图的属性。

**子图推理攻击**：攻击者旨在从图嵌入中推断图中是否包含某个特定的子结构（例如，是否存在一个三角形）。
*   **方法**：攻击者同样需要辅助图。他们训练一个本地模型来生成特定子图（如三角形）的嵌入。然后，结合完整的图嵌入和子图嵌入，训练一个攻击模型来判断该子图是否存在于原图中。评估表明，使用图嵌入与子图嵌入的差异作为特征训练模型效果较好。

将属性推理与子图推理结合，攻击者可以逐步缩小范围，尝试重建或复制有价值的原始图（如特定分子结构）。

**关键防御**：保护存储模型输出（后验分数、图嵌入）的数据库是防御上述攻击的基础。如果攻击者无法获取这些中间数据，攻击便无法实施。

## 模型提取攻击 🎯

上一节我们讨论了针对数据输出的攻击，本节中我们来看看针对模型本身的攻击。

模型提取攻击是指攻击者在不侵入系统的情况下，通过查询目标模型，忠实地复制其功能。假设目标模型通过一个安全的API向客户提供服务。

以下是攻击的工作流程：
1.  **构建查询图**：攻击者利用已有的数据（如用户资料）构建或合成图结构。在最坏情况下，他们可能使用算法生成最小有效结构。
2.  **查询与响应**：攻击者将查询图发送至目标API，获得响应。响应可能是节点嵌入、后验概率或t-SNE降维后的二维投影坐标。
3.  **训练代理模型**：攻击者同时将相同的查询图输入自己初始化的代理图神经网络模型。他们通过优化两个损失函数来训练代理模型，使其行为逼近目标模型：
    *   **结构损失**：确保代理模型与目标模型在欧几里得空间中保持相似的空间关系（例如，使用均方误差损失）。
    *   **任务损失**：确保代理模型在分类等任务上做出与目标模型相同的决策（例如，使用交叉熵损失）。

![](img/00f924c1e3c11236601f4993b56d9034_10.png)

**评估结果**：
*   攻击者仅需使用目标模型约3%的训练数据量进行查询，即可复制其大部分功能。
*   即使目标模型只返回信息量极少的二维t-SNE投影坐标，攻击者仍能以较好的性能复制模型功能。
*   常见的防御方法，如在API响应中添加高斯噪声扰动，效果有限。因为攻击者的损失函数会驱动代理模型跟踪被扰动的输出，最终仍能逼近目标模型的功能。

## 防御建议与总结 🛡️

![](img/00f924c1e3c11236601f4993b56d9034_12.png)

上一节我们了解了强大的模型提取攻击，本节中我们来看看有哪些防御思路和本课程的总结。

### 防御建议

![](img/00f924c1e3c11236601f4993b56d9034_14.png)

针对已讨论的攻击，我们可以采取以下措施：
1.  **加固基础设施**：严格保护存储原始训练数据、模型中间输出（后验分数、图嵌入）的数据库。这是防止数据泄露类攻击的第一道防线。
2.  **监控模型日志**：密切关注API查询模式。如果发现某个“客户”的查询行为异常（例如，突然发送大量非常规结构的图，导致模型表现波动），需要及时调查。
3.  **评估安全态势**：主动对部署的图神经网络模型进行渗透测试，了解其暴露在模型提取等新型攻击下的风险程度。
4.  **研究新型防御**：探索在不显著损害模型功能的前提下，能有效阻止模型功能被复制的防御机制（这是一个开放的未来研究方向）。

为了方便社区进行安全评估，相关攻击代码已开源发布。

![](img/00f924c1e3c11236601f4993b56d9034_16.png)

### 总结

![](img/00f924c1e3c11236601f4993b56d9034_18.png)

在本课程中，我们一起学习了图神经网络面临的主要安全威胁：
*   **链接重识别攻击**：通过泄露的后验分数推断节点间关系。
*   **属性与子图推理攻击**：通过泄露的图嵌入推断图属性或内部结构。
*   **模型提取攻击**：通过合法查询复制远程模型的功能。

这些攻击表明，图神经网络的输出和模型本身都蕴含敏感信息，必须将其纳入整体的安全和隐私保护框架中。保护数据存储、加强访问监控、并持续评估模型的安全态势，对于构建可靠的图神经网络应用至关重要。

![](img/00f924c1e3c11236601f4993b56d9034_20.png)

---
**Q&A 环节摘要**

*   **问**：这些攻击和防御策略是否同样适用于参数规模达十亿甚至千亿级别的大型图模型？
*   **答**：攻击的可行性可能与图的复杂性和决策边界的形状更相关，而不仅仅是参数规模。对于超大规模图（如数千万节点），如果其节点在嵌入空间中以密集集群形式分布，决策边界可能相对简单，攻击者仍有可能用相对较少的数据进行探测和复制。目前的研究主要在十万至二十万节点规模进行，超大规模下的情况仍需进一步探索。

![](img/00f924c1e3c11236601f4993b56d9034_22.png)

*   **问**：攻击中提到的“约3%训练数据”的规模，是否会随目标模型规模增大而改变？
*   **答**：核心在于理解目标模型的决策边界。对于大规模社交网络，虽然数据量大，但同类节点可能形成密集集群，使得决策边界简化。因此，攻击者可能仍不需要比例很高的查询数据就能理解并复制关键功能。但总体而言，模型越大、越复杂，攻击者可能需要更长时间的查询和更多的数据来覆盖不同的决策区域。